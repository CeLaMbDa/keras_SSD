{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"jtdAsWbi3LON","colab_type":"code","outputId":"dfb4735e-5e9b-4048-b510-b8e7bd9076dc","executionInfo":{"status":"ok","timestamp":1575695059033,"user_tz":-480,"elapsed":1565,"user":{"displayName":"Daniel Yurodidon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAR6_V2CzrDY0c9iRXjR8z1nRkDX-dHwU0ctquV=s64","userId":"04356559772290061707"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"StB1KgWiyhsV","colab_type":"code","outputId":"ac88a72e-072b-469e-8aad-b82664f7fe2d","executionInfo":{"status":"ok","timestamp":1575692959535,"user_tz":-480,"elapsed":9864,"user":{"displayName":"Daniel Yurodidon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAR6_V2CzrDY0c9iRXjR8z1nRkDX-dHwU0ctquV=s64","userId":"04356559772290061707"}},"colab":{"base_uri":"https://localhost:8080/","height":241}},"source":["!pip3 install scipy==1.2.0\n","!pip3 install keras==2.3.0\n","!pip3 install tensorflow==1.13.0"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: scipy==1.2.0 in /usr/local/lib/python3.6/dist-packages (1.2.0)\n","Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.2.0) (1.17.4)\n","Requirement already satisfied: keras==2.3.0 in /usr/local/lib/python3.6/dist-packages (2.3.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.0.8)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.12.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.2.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.17.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (3.13)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.1.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (2.8.0)\n","\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.13.0 (from versions: 0.12.1, 1.0.0, 1.0.1, 1.1.0rc0, 1.1.0rc1, 1.1.0rc2, 1.1.0, 1.2.0rc0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.3.0rc0, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.4.0rc0, 1.4.0rc1, 1.4.0, 1.4.1, 1.5.0rc0, 1.5.0rc1, 1.5.0, 1.5.1, 1.6.0rc0, 1.6.0rc1, 1.6.0, 1.7.0rc0, 1.7.0rc1, 1.7.0, 1.7.1, 1.8.0rc0, 1.8.0rc1, 1.8.0, 1.9.0rc0, 1.9.0rc1, 1.9.0rc2, 1.9.0, 1.10.0rc0, 1.10.0rc1, 1.10.0, 1.10.1, 1.11.0rc0, 1.11.0rc1, 1.11.0rc2, 1.11.0, 1.12.0rc0, 1.12.0rc1, 1.12.0rc2, 1.12.0, 1.12.2, 1.12.3, 1.13.0rc0, 1.13.0rc1, 1.13.0rc2, 1.13.1, 1.13.2, 1.14.0rc0, 1.14.0rc1, 1.14.0, 1.15.0rc0, 1.15.0rc1, 1.15.0rc2, 1.15.0rc3, 1.15.0, 2.0.0a0, 2.0.0b0, 2.0.0b1, 2.0.0rc0, 2.0.0rc1, 2.0.0rc2, 2.0.0, 2.1.0rc0)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for tensorflow==1.13.0\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"53rQ5bKh4oTE","colab_type":"code","colab":{}},"source":["import os\n","os.chdir(\"/content/drive/My Drive/SSD/\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kd1cstgUUc2Y","colab_type":"code","colab":{}},"source":["import src.SSD as SSD\n","from src.Utils import *\n","from src.Generators import *\n","from src.Loss import *\n","import pickle as pk\n","import keras\n","\n","classes = 21\n","priors = pk.load(open('./priorboxes_300.ple', \"rb\"))\n","# preload = pk.load(open('./transponder.ple', \"rb\"))\n","utils = BBoxUtility(classes, priors, 0.6, 0.45)\n","\n","def schedule(epoch, decay=0.9):\n","    return base_lr * decay**(epoch)\n","\n","callbacks = [keras.callbacks.LearningRateScheduler(schedule), \n","              keras.callbacks.ModelCheckpoint('./checkpoints/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n","                                             verbose=1,\n","                                             save_weights_only=True)]\n","\n","transponder = Yielder(\"../VOC2007/JPEGImages/\", \"../VOC2007/Annotations/\",\n","                          (300, 300, 3), 1, utils, classes=VOC2007MAP, end=4800)\n","confrimer = Yielder(\"../VOC2007/JPEGImages/\", \"../VOC2007/Annotations/\",\n","                          (300, 300, 3), 1, utils, classes=VOC2007MAP, start=5000)\n","\n","# transponder = Yielder(\"../RBC-dataset/JPEGImages/\", \"../RBC-dataset/Annotations/\",\n","#                           (300, 300, 3), 16, utils, classes=RBCMAP)\n","\n","# confrimer = Yielder(\"../RBC-dataset/JPEGImages/\", \"../RBC-dataset/Annotations/\",\n","#                           (300, 300, 3), 16, utils, classes=RBCMAP, start=300, end=343)\n","\n","\n","model = SSD.SSD((300, 300, 3), classes)\n","\n","\n","from keras import backend as K\n","\n","def r2_keras(y_true, y_pred):\n","    SS_res =  K.sum(K.square(y_true - y_pred)) \n","    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n","    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n","\n","base_lr = 1e-4\n","optim = keras.optimizers.Adam(lr=base_lr)\n","model.compile(optimizer=optim, loss=MultiboxLoss(classes, neg_pos_ratio=2.0).compute_loss, \n","              metrics=['mae', 'categorical_accuracy', 'acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jNgCo5_u4u8E","colab_type":"code","outputId":"7b6763cf-9618-433b-8922-cf4c68bbdc7b","executionInfo":{"status":"error","timestamp":1575690475641,"user_tz":-480,"elapsed":77593,"user":{"displayName":"Daniel Yurodidon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAR6_V2CzrDY0c9iRXjR8z1nRkDX-dHwU0ctquV=s64","userId":"04356559772290061707"}},"colab":{"base_uri":"https://localhost:8080/","height":377}},"source":["model.load_weights(\"weights_SSD300.hdf5\", by_name=True)\n","\n","freeze = ['block1_1', 'block1_2', 'pool1', 'block2_1',\n","          'block2_2', 'pool2',\n","          'block3_1', 'block3_2''block3_3', 'pool3']\n","          # 'block4_1', 'block4_2', 'block4_3']\n","for layers in model.layers:\n","    if layers.name in freeze:\n","        layers.trainable = False\n","\n","\n","epoch = 20\n","\n","history = model.fit_generator(transponder.generate(), 4800, epoch, nb_val_samples=211,\n","                              nb_worker=30, use_multiprocessing=True,\n","                              validation_data=confrimer.generate(), verbose=1, callbacks=callbacks)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n","  app.launch_new_instance()\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., 4800, 20, use_multiprocessing=True, validation_data=<generator..., verbose=1, callbacks=[<keras.ca..., validation_steps=211, workers=30)`\n","  app.launch_new_instance()\n","/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n","/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n","  UserWarning('Using a generator with `use_multiprocessing=True`'\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["4800/4800 [==============================] - 305s 64ms/step - loss: 4.2838 - mae: 0.1663 - categorical_accuracy: 5.4873e-04 - acc: 5.4873e-04 - val_loss: 4.0693 - val_mae: 0.1648 - val_categorical_accuracy: 1.0503e-04 - val_acc: 1.0503e-04\n","\n","Epoch 00001: saving model to ./checkpoints/weights.01-4.07.hdf5\n","Epoch 2/20\n","4800/4800 [==============================] - 300s 63ms/step - loss: 4.1428 - mae: 0.1649 - categorical_accuracy: 9.1643e-05 - acc: 9.1643e-05 - val_loss: 2.8592 - val_mae: 0.1649 - val_categorical_accuracy: 8.9932e-05 - val_acc: 8.9932e-05\n","\n","Epoch 00002: saving model to ./checkpoints/weights.02-2.86.hdf5\n","Epoch 3/20\n","4038/4800 [========================>.....] - ETA: 47s - loss: 4.1263 - mae: 0.1649 - categorical_accuracy: 9.0600e-05 - acc: 9.0600e-05"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RsADfZ5Yx94M","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"7azG7GDdFXCF","colab_type":"code","colab":{}},"source":["model.save_weights('./model_weights.wt')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hCO8pSbftqFI","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"7c9YOwqXrVA0","colab_type":"code","outputId":"f1d92e20-2d8e-4c31-c8ee-6bc9771e02f0","executionInfo":{"status":"ok","timestamp":1575694549783,"user_tz":-480,"elapsed":1224,"user":{"displayName":"Daniel Yurodidon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAR6_V2CzrDY0c9iRXjR8z1nRkDX-dHwU0ctquV=s64","userId":"04356559772290061707"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["from keras.preprocessing import image\n","from scipy.misc import imread\n","from scipy.misc import imresize\n","# from src.SSD import SSD\n","# from src.Utils import BoxUtils\n","import pickle as pk\n","from keras.applications.imagenet_utils import preprocess_input\n","import numpy as np\n","inputs = []\n","images = []\n","img_path = \"../VOC2007/JPEGImages/000005.jpg\"\n","img = image.load_img(img_path, target_size=(300, 300))\n","img = image.img_to_array(img)\n","images.append(imread(img_path))\n","inputs.append(img.copy())\n","inputs = preprocess_input(np.array(inputs))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: `imread` is deprecated!\n","`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n","Use ``imageio.imread`` instead.\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"n2YRWmPc302x","colab_type":"code","colab":{}},"source":["\n","import matplotlib.pyplot as plt\n","preds = model.predict(inputs, batch_size=1, verbose=1)\n","results = utils.detection_out(preds)\n","for i, img in enumerate(images):\n","    for each in results:\n","      for e in each:\n","        print(e)\n","    # Parse the outputs.\n","    det_label = results[i][:, 0]\n","    det_conf = results[i][:, 1]\n","    det_xmin = results[i][:, 2]\n","    det_ymin = results[i][:, 3]\n","    det_xmax = results[i][:, 4]\n","    det_ymax = results[i][:, 5]\n","\n","    # Get detections with confidence higher than 0.6.\n","    top_indices = [i for i, conf in enumerate(det_conf) if conf >= 0.65]\n","\n","    top_conf = det_conf[top_indices]\n","    top_label_indices = det_label[top_indices].tolist()\n","    top_xmin = det_xmin[top_indices]\n","    top_ymin = det_ymin[top_indices]\n","    top_xmax = det_xmax[top_indices]\n","    top_ymax = det_ymax[top_indices]\n","\n","    colors = plt.cm.hsv(np.linspace(0, 1, 4)).tolist()\n","\n","    plt.imshow(img / 255.)\n","    currentAxis = plt.gca()\n","\n","    for i in range(top_conf.shape[0]):\n","        xmin = int(round(top_xmin[i] * img.shape[1]))\n","        ymin = int(round(top_ymin[i] * img.shape[0]))\n","        xmax = int(round(top_xmax[i] * img.shape[1]))\n","        ymax = int(round(top_ymax[i] * img.shape[0]))\n","        score = top_conf[i]\n","        label = int(top_label_indices[i])\n","#         label_name = voc_classes[label - 1]\n","        display_txt = '{:0.2f}, {}'.format(score, label)\n","        coords = (xmin, ymin), xmax-xmin+1, ymax-ymin+1\n","        color = 'b'\n","        currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=color, linewidth=2))\n","        currentAxis.text(xmin, ymin, display_txt, bbox={'facecolor':color, 'alpha':0.5})\n","    \n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nS5UssoI5HIV","colab_type":"code","outputId":"5ec31b15-a248-4951-eb3f-18d9182bd675","executionInfo":{"status":"ok","timestamp":1575695564850,"user_tz":-480,"elapsed":41322,"user":{"displayName":"Daniel Yurodidon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAR6_V2CzrDY0c9iRXjR8z1nRkDX-dHwU0ctquV=s64","userId":"04356559772290061707"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1hdsCZruDdecembpwuP1kHPCxFwBjNFvb"}},"source":["\n","import tensorflow as tf\n","\n","import pickle as pk\n","# priors = pk.load(open(\"./priorboxes_300.ple\", 'rb'))\n","\n","\n","b = transponder.generate()\n","\n","ret = next(b)\n","print(ret[0].shape, ret[1].shape)\n","image = ret[0]\n","image = image.reshape(1, 300, 300, 3)\n","# for each in image:\n","#   for e in each:\n","#     print(e)\n","ann = ret[1].astype('float32')\n","# for each in ann:\n","#   for e in each:\n","#     print(e)\n","print(ann.shape)\n","\n","ret = model.predict(image)\n","for each in ret:\n","  for e in each:\n","    print(e)\n","print(ann.shape, ret.shape)\n","loss =  MultiboxLoss(21).compute_loss(ann, ret)\n","sess = tf.Session()\n","print(sess.run(loss))"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"RsVLINCzWUjp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}